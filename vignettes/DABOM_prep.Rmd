---
title: "2.0) Preparing Data for DABOM"
author: Kevin See
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{2.0) Preparing Data for DABOM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r, echo = FALSE, message = FALSE, warning = FALSE, results = "hide"}
# knitr options
knitr::opts_chunk$set(
collapse = TRUE,
warning = FALSE,
message = FALSE,
echo = TRUE,
comment = "#>"
)

library(knitr)
```


# Introduction

One purpose of the `PITcleanr` package is to prepare PIT tag observations for the Dam Adult Branch Occupancy Model ([DABOM](https://github.com/BiomarkABS/DABOM)). DABOM estimates upstream movement probabilities across a branching stream network. One of the major assumptions in that model is that fish are making a one-way trip upstream, meaning they aren't moving into one tributary, turning around and moving into another. In reality, such movements certainly happen, but those detections must be "cleaned" before running the model. This means that if a tag is detected in multiple branches, someone must decide which branch (i.e, stream or river) represents their spawning trajectory, and the detections from the other branches are deleted. `PITcleanr` can examine complete tag histories from [PTAGIS](https://ptagis.org/) for a list of tags and help identify which tags have detections in multiple branches, and provide a suggestion for which detections to retain.

In this vignette, we will also use many functions from the `tidyverse` [group of packages](https://www.tidyverse.org/), so we load that as well:

```{r load-package}
library(PITcleanr)
library(tidyverse)
```


# Data Preparation

The following sections, [Querying Detection DAta from PTAGIS] and [Compressing Data], are pulled directly from the introductory `PITcleanr` vignette which can be accessed [here](Prep_PIT_data.html). That vignette explains additional functionality available from `PITcleanr` and can also be accessed using:

```{r, eval = F}
vignette("Prep_PIT_data",
         package = "PITcleanr")
```

The sections following those are more directly related to preparing your data for use in ([DABOM](https://github.com/BiomarkABS/DABOM)).


## Querying Detection Data from PTAGIS

```{r child = "../man/fragments/query-ptagis.Rmd"}
```

These detections can then be "compressed" into a more manageable format as follows...


## Compressing Data

```{r child = "../man/fragments/compress-data.Rmd"}
```


## Additional Data Prep for DABOM

### Site Configuration

```{r, echo = F, results = "hide"}
array_configuration = buildConfig()

# customize some pieces
configuration = array_configuration %>%
  # first, for example, 'LNF' and 'LEAV' are re-coded into a single node 'LNF'
  mutate(node = ifelse(site_code %in% c('LNF', 'LEAV'),
                       'LNF',
                       node),
         # these three nodes are all re-coded to a single 'TUM'
         node = ifelse(site_code %in% c('TUF', 'TUMFBY', 'TUM'),
                       'TUM',
                       node),
         node = ifelse(site_code == 'CHIWAC',
                       'CHWA0',
                       node),
         node = ifelse(site_code %in% c('CHIWAR', 'CHIWAT'),
                       'CHLA0',
                       node),
         node = ifelse(site_code == 'CHIW',
                       'CHLA0',
                       node),
         # In this case, PIT tags from carcass recoveries in the Chikamin River are
         # grouped with the upper 'CHU' array
         node = ifelse(site_code == 'CHIKAC',
                       'CHUA0',
                       node),
         node = ifelse(site_code == 'NASONC',
                       'NALA0',
                       node),
         node = ifelse(site_code == 'WHITER',
                       'WTLA0',
                       node),
         node = ifelse(site_code == 'LWENAT',
                       'LWNA0',
                       node)) %>%
  distinct()

```

The default operation of `compress()` maps each PTAGIS site code as its own node, but that may not always be desirable, especially in the case of DABOM. For DABOM, nodes typically correspond to an upper or lower array at a detection site, labeled with the site code and either `A0` or `B0`, respectively. The user may instead choose to provide their own nodes for DABOM. Custom nodes can be used by providing a site configuration to the `configuration` argument of `compress()`. More information on site configuration can be found in that section of the [introductory vignette](Prep_PIT_data.html).

Let's re-run the `compress()` function on our `ptagis_file`, except in this case we'll provide a custom `configuration`.

```{r}
# re-run compress(), except provide configuration
comp_obs = compress(ptagis_file,
                    configuration = configuration)

```


### Filtering Detections

In preparing data for DABOM, it is usually a good idea to filter the detections from PTAGIS so each tag starts at the same site, in our case, Tumwater Dam, and filter out any detections that occur prior to that date. In our example, we will get the date of the first detection of each tag at Tumwater Dam, which could include the mark event, and call that the `$start_date`. We the remove any detections that occur prior to that date `filter(min_det >_ start_date)`. Finally, we quickly re-order the slots after removing those detections.

```{r}
obs = comp_obs %>%
  # get the first detection of each tag at Tumwater Dam, which could include the mark
  left_join(comp_obs %>%
              filter(node == "TUM",
                     event_type_name %in% c("Mark", "Recapture")) %>%
              group_by(tag_code) %>%
              filter(min_det == min(min_det)) %>%
              summarise(start_date = min_det,
                        .groups = "drop"),
            by = "tag_code") %>%
  # filter any detections that occur before the start_date
  filter(min_det >= start_date) %>%
  # re-calculate the "slots" for each tag_code
  group_by(tag_code) %>%
  mutate(slot = slot - min(slot) + 1) %>%
  ungroup()

```


### "Parent-Child" Relationships

Parent-child tables are also described in further detail in the [introductory vignette](Prep_PIT_data.html) of `PITcleanr`. Briefly, a parent-child table describes the closest downstream detection location (parent) for each detection location (child). If a tag is observed at a child location, it must have moved past the parent location. `PITcleanr` constructs parent-child tables assuming an upstream movement, which is appropriate for DABOM. The package will also augment the parent-child table of detection sites with detection nodes, based on the configuration file. The following provides an example of building a parent-child table using functions in `PITcleanr` including adding nodes with the `addParentChildNodes()`.

First, extract PTAGIS sites present in our `ptagis_file` using the `extractSites()` function. We'll focus just on those sites within the Wenatchee subbasin:

```{r extract-sites}
sites_sf = extractSites(ptagis_file,
                        as_sf = T,
                        min_date = "20150501",
                        configuration = configuration)
# focus on sites within Wenatchee subbasin
sites_sf = sites_sf %>%
  filter(grepl("754.", rkm),
         # remove a few sites we don't care about
         !site_code %in% c("LWE", "ICICLC"))
```

Next, download the flowlines using the `queryFlowlines()` function and save those to a new object `flowlines`:

```{r query-flowlines}
# query the flowlines
nhd_list = queryFlowlines(sites_sf = sites_sf,
                          root_site_code = "TUM",
                          min_strm_order = 2,
                          dwnstrm_sites = T,
                          dwn_min_stream_order_diff = 2)

# compile the upstream and downstream flowlines
flowlines = nhd_list$flowlines %>%
  rbind(nhd_list$dwn_flowlines)
```

Build the initial `parent_child` using the `buildParentChild()` function and make some fixes using `editParentChild()`:

```{r parent-child}
parent_child = sites_sf %>%
  filter(! site_code %in% c("UWE", "LWE")) %>%
  buildParentChild(flowlines) %>%
  editParentChild(fix_list = list(c(NA, "ICL", "TUM"),
                                  c(NA, "PES", "TUM"),
                                  c("LNF", 'ICM', 'ICL')),
                  switch_parent_child = list(c("ICL", 'TUM')))

```

Finally, add nodes using the `addParentChildNodes()` function and view the resulting `parent_child_nodes`:

```{r}
parent_child_nodes = addParentChildNodes(parent_child,
                                         configuration = configuration)

# view expanded parent-child table
parent_child_nodes

```

More detailed information on site configuration files, parent-child relationships, and the functions used in the above section can be found in the [1.0) Querying, Compressing, and Making Sense of PIT Tag Detection Data](Prep_PIT_data.html) of `PITcleanr`.


# Filtering Detections for DABOM

Based on the parent-child table, and the order of detection nodes through time, `PITcleanr` can assign a direction of movement to each observation, using the function `addDirection`. If the compressed detections have been filtered so they all start at the tagging location, then those initial observations will be labeled with direction "start". Subsequently, "forward" indicates upstream movement, and "backward" indicates downstream movement. A direction of "unknown" indicates the tag has shifted to a different branch in the stream network.

The function `filterDetections` incorporates those directions and adds two columns to indicate whether each detection should be retained for DABOM. For tags with straightforward detections (i.e. all detections appear to have one-way directional movement), the added columns `auto_keep_obs` and `user_keep_obs` will be marked `TRUE`. For tags with less straightforward movement patterns, `PITcleanr` assumes that the last detection with movement noted as "forward" or "unknown" (or "start") is the spawning location, and attempts to mark the `auto_keep_obs` column as `TRUE` for the last detections along that movement path. For these tags, `filterDetections` returns `NA`'s in the `user_keep_obs` column. 

`filterDetections` also allows the user to input a maximum observed date (`max_obs_date`), which will mark all detections after that date as invalid (`auto_proc_obs` will be `FALSE`). This may be useful for steelhead to filter out kelting detections, or for Chinook when ghost tags from carcasses or that were expelled during spawning may be observed.

```{r}
prepped_df = filterDetections(compress_obs = obs,
                              parent_child = parent_child_nodes,
                              max_obs_date = "20150930")
```

```{r}
prepped_df %>%
  filter(is.na(user_keep_obs)) %>%
  filter(tag_code == "3D9.1C2DE4B17E") %>%
  select(tag_code:node, 
         min_det,
         node_order:auto_keep_obs)
```

The next step would be for a user to filter the prepared data for all rows with `user_keep_obs == NA`, and then fill in the `user_keep_obs` column by hand for each node. These decisions could be guided by the `auto_keep_obs` column (`PITcleanr`'s best guess), but could also be informed by the date of detections and the user's biological knowledge of the system. Before sending the data along to DABOM, all the missing `user_keep_obs` rows should be filled out. 

# Wrapper Function

`PITcleanr` includes a wrapper function that starts with the user-defined parent-child table and either the initial compressed observations or the PTAGIS file and configuration file, and performs several steps:

* Adds a start date corresponding to the date when a tag was marked or recaptured at the starting node (`start_node`)
* Provides an argument `min_obs_date` that will filter out observations prior to that date
* Runs the `filterDetections()` function
* If desired, saves the output as a csv or Excel file, to make it easier to examine tag histories with less than straightforward detection paths

If a user has a parent-child table and configuration file built from a previous year, or by hand, this function makes it very easy to prepare a new year's worth data for DABOM.

```{r, eval = F}
# using the compressed observations
prepped_df = prepWrapper(compress_obs = comp_obs,
                         parent_child = parent_child_nodes,
                         min_obs_date = "20150301",
                         max_obs_date = "20150930")

# using the PTAGIS file and configuration file
prepped_df = prepWrapper(ptagis_file = ptagis_file,
                         configuration = configuration,
                         parent_child = parent_child_nodes,
                         min_obs_date = "20150301",
                         max_obs_date = "20150930")
```

